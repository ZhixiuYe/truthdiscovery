\documentclass[../main.tex]{subfiles}
\begin{document}

The fundamental problem of truth discovery is to resolve conflicts in a set of
claims from different sources. A na\"ive approach is to apply a \emph{majority
vote}, where the claim made by the largest number of sources is accepted.
Unfortunately, this is prone to yield poor results when the sources are not all
equally trustworthy. For example, the study in \cite{vosoughi} found that false
information on Twitter is shared more quickly and more widely than true
information. Applying a majority vote in the Twittersphere would therefore, in
many cases, select the \emph{false} information as correct.

The problem with the majority vote is that all sources are treated identically:
a claim from one source carries as much weight as a claim from any other. This
is contrary to how we judge the veracity of statements in everyday life, where
claims from trusted colleagues have considerably more weight that claims from
unknown persons (and especially people known to be \emph{untrustworthy}). Trust
can therefore be a valuable tool in resolving conflicting information, since
one expects that trustworthy sources are more likely to make accurate claims
than untrustworthy sources are.

Truth discovery therefore has two components: determining \emph{trust} and
\emph{belief} in sources and claims, and resolving conflicts in data. These are
tightly linked, since the trust evaluation is based on the claims in the input
data, and the claims to accept are based on the trust evaluation.

Presently we outline related areas in the literature that deal with resolving
conflicts and trust analysis, before providing some background on truth
discovery itself. Then we review existing work relevant to the practical and
theoretical components of the project.

\section{Related Areas}
\subsection{Resolving Conflicts in Data}

There are numerous areas in the existing literature that deal with resolving
conflicts in data. In data mining, \emph{data fusion} considers aggregating
data from different sources into a single representation. Various approaches
have been suggested (see \cite{bleiholder} for a review): for example, taking a
majority vote (as discussed above), taking the most recent value as correct, or
ignoring objects entirely when a conflict exists.

In collective annotation \cite{kruger}, multiple individuals assign labels
(annotations) to objects, which are to be aggregated into a single collective
annotation. Different individuals may not agree on the appropriate labels for a
given object; \emph{aggregation functions} consider how to obtain the
collective annotation given these conflicts.

Belief revision \cite{gardenfors} is set out in a logical framework, and
considers how to update a knowledge base upon receiving new information that
could cause the knowledge base to be inconsistent.

Argumentation theory \cite{hofa_semantics} takes an abstract view and considers
a set of `arguments' which conflict with each other (known as `attacking'). The
structure of the arguments is abstracted away, and only the network of which
arguments attack each other is considered. The aim is then to find sets of
arguments that are acceptable and consistent.

In a more general sense, social choice also deals with conflicts in data. Here
voters express preferences for a number of `alternatives' (e.g. candidates for
an election), and a social ordering of the alternatives is sought that reflects
the will of the voters. Difficulties may arise when there is no consensus among
the voters -- e.g. one voter's favourite outcome could be another's least
favourite. Although the notion of fairness present here is not applicable
to truth discovery, the issue of conflicts in the preferences of voters is
relevant.

\subsection{Trust Analysis}

Trust has been studied in many different domains for different applications
(see \cite{momani_challa} for a survey). In the social sciences and economics,
trust between humans has been considered for the effects on economic
transactions. E-commerce sites such as eBay use the concept of trust and
reputation of sellers to inform buyers.

In wireless sensor networks, nodes communicate to relay sensor data and to help
route packets through the wireless network. Nodes are required to report
accurate data and behave cooperatively: this may fail due to system failure
(e.g. hardware problems) or malicious interference from an adversary. Various
approaches have been suggested for analysing the trust of nodes in such
networks (e.g. see section 4.4 in \cite{momani_challa}) to mitigate effects of
misbehaviour. Trust analysis is applied in a similar way in P2P and ad-hoc
mobile networks.

It should be noted that some of these approaches to evaluating trust compute
`local' measures of trust from the perspective of a particular node. For
example, a sensor in a network may evaluate the trust of its neighbours based
on its interactions with them. The trust assigned to a given node may therefore
vary as it is evaluated from different perspectives. This is not the case with
truth discovery, where we seek an objective `global' notion of trust in sources
based only on the claims made.

Other works do not aim to \emph{compute} trust, but instead use trust
relationships between `agents' in a multi-agent system for some purpose. One
example is trust-based recommendation systems \cite{andersen}, where an agent
is given a recommendation for an item of interest based on the recommendations
of the agents it trusts. Other examples include personalised ranking systems
\cite{altman_personalised}, trust-based argumentation \cite{tang} and
trust-based belief revision \cite{booth}.

The trust considered here is again from the perspective of a given agent.
Nevertheless ideas from these areas still may be relevant to truth discovery.

From a theoretical point of view, Marsh \cite{marsh} provides a formal model
for trust in multi-agent systems.

\section{Truth Discovery Background}

In the preceding sections truth discovery has been discussed only informally.
Here we outline more precisely the main concepts in the basic form of truth
discovery, and discuss the various extensions to this basic form that have been
addressed in the literature. More information can be found in survey papers on
truth discovery methods \cite{li_survey, gupta_han_survey}.

A \emph{source} is an entity that provides information, called \emph{facts},
about \emph{objects}. A source may provide only one fact for a single object.
Different sources may provide different facts for the same object; a fact need
not be `true'. It is often assumed that for each object there is a unique true
fact. In the basic form of truth discovery, the nature of the facts is
irrelevant, and they are treated as categorical values\footnotemark.

\footnotetext{
    Some approaches instead make use of the specific data types of the facts in
    their calculations (e.g. \cite{li_conflicts}).
}

A truth discovery algorithm takes the input of sources, facts, objects and the
facts claimed by each source, and computes a \emph{trust score} for each source
and a \emph{belief score} for each fact. Higher scores represent more
trustworthy sources and more believable facts\footnotemark. For each object,
the fact with the highest belief score is then taken as the true fact.

\footnotetext{
    Some algorithms do not output belief scores for facts, and instead output
    a single `identified truth' for each object \cite{zhang_qi_tang,
    li_conflicts, yang, zhi}. However we can regard this as assigning a belief
    score of 1 to the identified truth for each object, and 0 for all other
    facts.
}

The input may be represented mathematically in various ways; this will be
discussed in more detail in section \ref{sec:theory_approach}. \todo{check
forward reference}

In practise, most algorithms compute trust and belief scores \emph{iteratively}
until convergence. First, facts are assigned initial belief scores. At each
iteration, the trust scores for sources are updated based on the current belief
scores for the facts they claim; then the belief scores are updated based on the
current trust scores for the sources. This mutual dependence of trust and
belief scores is hoped to encode the idea that trustworthy sources are ones
that claim believable facts, and believable facts are those claimed by
trustworthy sources.

This basic formulation is a simple representation of the real-world, and a
number of extensions have been addressed to deal with more complex situations.
Some approaches extend the basic model by requiring more information in the
input (e.g. a set of `ground truths' for semi-supervised truth discovery),
whereas others keep the same basic input but consider more nuanced issues in
their computation of trust and belief scores (e.g considering copying amongst
sources). Extensions include:
\begin{itemize}
\item implications between facts: distinct but similar facts may support each
other \cite{yin_han_yu}

\item heterogeneous data: facts may have different data types (e.g.
categorical or continuous values) \cite{li_conflicts}

\item correlations between objects: the true facts for similar objects may be
similar \cite{yang}

\item hardness of facts: some questions are easier to answer than others, and
it should not be possible for a source to raise its trust score by simply
answering many `easy' questions \cite{galland}

\item incorporating prior domain knowledge: prior knowledge about the domain
can inform belief scores \cite{pasternack}

\item sparsity: each source may contribute only a small number of claims
\cite{zhang_sparse}

\item semi-supervised truth discovery: a selection of `ground truths' are known
in advance \cite{yin_supervised}

\item copying between sources: source may \emph{copy} from each other, and
doing so should not increase the trustworthiness of an otherwise untrustworthy
source \cite{dong}

\item time-varying truth: the true fact for an object may vary over time
\cite{dong}

\item streaming data: data is often received gradually over time \cite{zhao}

\end{itemize}

% Many different approaches to truth discovery have been suggested in the
% literature. Whilst they all tackle the same basic problem, there is variety in
% the precise representation of the problem, the input and output to truth
% discovery algorithms, and the methods they employ. For example, some algorithms
% output numeric \emph{belief} or \emph{confidence} scores for each claim
% \cite{pasternack, yin_han_yu, galland, yin_supervised}, whereas others consider
% each claim to be related to a single \emph{object}, and output only the most
% likely true claim for each object \cite{zhang_qi_tang, li_conflicts, yang,
% zhi}. The different models in use will be discussed in detail in section
% \ref{sec:approach}. \todo{check future reference}

% Most algorithms operate on the principle that trustworthy sources are ones that
% make believable claims, and believable claims are ones made by trustworthy
% sources. This idea is implemented in various ways, using methods including
% \begin{itemize}
% \item heuristics for trust and belief scores
% \cite{pasternack}

% \item probabilistic methods, where trust/belief scores represent the
% \emph{probability} that a source claims true facts or that a claim is true

% \item optimisation based methods

% \item statistical methods, e.g. where the trustworthiness of sources and the
% true claims are treated as latent random variables, and statistical methods are
% used to determine the most probable values of these variables given the
% available evidence.

% \end{itemize}

% \todo{Citations for the above}

\section{Existing Work}
\subsection{Software Implementations}

Due to the wide range of domains in which truth discovery may be applied and
the variety of approaches and additional considerations beyond the basic model
(some of which are domain specific), there is not likely to be a single
algorithm that is best suited for all applications.

Instead, for a given problem it is necessary to try several algorithms, or even
tailor a bespoke one, to achieve the best results. Note that even evaluation
may be domain specific: run time and memory efficiency may be critical in some
cases (e.g. when dealing with large volumes of data in a scenario where
real-time results are desired), whereas some applications may be insensitive to
long run times but require precise accuracy.

For this reason, there is a need for an openly available and extendible
software framework for truth discovery, which allows different algorithms to be
evaluated and compared in a uniform environment. When faced with a particular
truth discovery problem, users may then run many algorithms on their data
without additional effort for each algorithm. An easily extendible framework
will allow them to define their own metrics for evaluation that are suitable
for the dataset in question, and even modify algorithms to suit the type of
data if required.

Despite the wide interest in truth discovery in research papers, there are few
open source software implementations. One such implementation is
\emph{spectrum}\footnotemark, available on GitHub. This library implements some
algorithms from the literature, but lacks proper documentation, does not
provide a uniform interface for getting results across algorithms, and does not
support evaluating results for datasets for which some true values are already
known. It also does not provide fine-tuned control for the running of
algorithms, such as the threshold for determining when trust and belief scores
have converged.

\footnotetext{\url{https://github.com/totucuong/spectrum}}

Another open source library is DAFNA-EA\footnotemark, which is the
implementation behind the comparative study in \cite{waguih}. Whilst extensive
in the number of algorithms implemented, its capability for evaluating
performance and generation of \emph{synthetic data}, it lacks documentation to
allow its code to be extended (i.e. for users to define their own evaluation
metrics or algorithms), and is not geared towards real-world applications of
truth discovery. Additionally, a web interface is reportedly available, which
may improve accessibility for non-technical users, but is not operational at
the time of writing.

\footnotetext{\url{https://github.com/daqcri/DAFNA-EA}}

Other truth discovery implementations are available on GitHub and
elsewhere\footnotemark, but these are generally repositories containing code
used in the production of a research paper rather than general purpose
libraries.

\footnotetext{
    e.g.
    \url{https://github.com/lvlingyu11/Truth-Discovery-for-Crowdsourcing-Data}
    and \url{https://github.com/MengtingWan/KDEm}
}

To produce a software framework for truth discovery that achieves the goals
stated above and which addresses the deficiencies of the existing frameworks,
this project will implement a selection of algorithms from the literature in a
uniform way with a focus on extendability, which will include comprehensive
documentation of both the code and the user interface. Fine-tuned control of
parameters for initialising and running algorithms will be available. It will
also identify standard metrics for evaluating algorithms (including generation
of synthetic datasets), and provide means of comparing algorithms with respect
to those metrics.

\subsection{Theoretical Work}

Many of the truth discovery algorithms in the literature are supported by some
form of theoretical analysis. For example, the survey in
\cite{gupta_han_survey} analyses the time complexity of various algorithms, the
convergence of \emph{semi-supervised truth finder} is proved in
\cite{yin_supervised}, and the approach in \cite{xiao} is proven to converge to
find the true facts under assumptions on the distributions of source
reliability. In \cite{xiao_thesis}, a probabilistic framework termed
\emph{Unified Truth Discovery} is developed, and theoretical properties of this
framework are proved under certain mild assumptions.

A limitation of this kind of theoretical analysis is that the results apply
only to a single algorithm or class of algorithm. These results, whilst
important in their own right, are not general enough to apply to truth
discovery as a whole, and depend on the specific ideas and approaches in use.

As far as I am aware, at the time of writing there is no general theoretical
framework capable of modelling \emph{all} truth discovery algorithms, which
allows general properties of such algorithms to be studied. Developing such a
framework would allow algorithms to be compared with respect to their
theoretical properties as opposed to purely practical ones, something which has
not been done in the literature to date.

A general theory of truth discovery would also facilitate deeper comparison
between truth discovery and other areas in the literature. For example, it was
noted above that truth discovery bears similarity to belief revision,
argumentation theory and, in a more general sense, social choice. Each of these
areas have rich formal foundations which have provided useful results for both
theoretical and practical purposes; developing similar foundations for truth
discovery may reveal deeper similarities and allow results in these areas to be
applied to truth discovery.

An approach that has seen great success in social choice is the \emph{axiomatic
method}, where axioms (desirable properties) of voting rules are stated, and
rules are compared with respect to these properties. Such analysis can provide
deep results; for example, K. Arrow's famous impossibility theorem \cite{arrow}
shows that it is impossible for a voting rule to simultaneously satisfy a few
simple axioms that one would reasonably expect of a fair voting rule, thus
proving a fundamental limitation of voting rules in general. The axiomatic
approach has also been successfully applied in the related areas of ranking
\cite{altman_foundations, altman_personalised}, recommendation \cite{andersen,
lev}, collective annotation \cite{kruger} and belief revision \cite{agm}.

This project will aim to define a theoretical framework for truth discovery
that is general enough for any algorithm to be modelled, independent of the
algorithms specific approach. Following the axiomatic method employed in social
choice and related areas, axioms for truth discovery algorithms will be
developed to encode desirable properties. To demonstrate the framework's
suitability as a tool for analysing real-world truth discovery algorithms,
\emph{Sums} \cite{pasternack} will be defined formally and analysed with
respect to the developed axioms.

\end{document}
