\documentclass{article}
\date{February 2019}
\author{Joe Singleton}
\title{
    Notes on theory of truth discovery algorithms
}

% Packages:
\usepackage{xcolor}
\usepackage{multicol}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{amsthm}
% \usepackage[top=1cm, bottom=1cm, left=2cm, right=2cm]{geometry}

% Settings
\hypersetup{
	colorlinks,
	citecolor={blue!80!black},
	urlcolor={blue!80!black},
	linkcolor={blue!80!black}
}

% Maths environments
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\theoremstyle{plain}
\newtheorem{axiom}{Axiom}

\begin{document}
\maketitle
% \begin{multicols}{2}

\section{Frameworks for truth-discovery used in existing literature}

\subsection{Li et. al. survey}
\label{sec:li}

A 2015 survey by Li et. al. {\cite{li_survey}} defines truth-discovery as
follows.

\begin{itemize}
\item We have a set of sources $\mathcal{S}$, and a set of objects $\mathcal{O}$
\item Each source $s$ claims a value $v_{o}^{s}$ for some objects $o$ (not
necessarily \emph{all} objects)
\item Truth-discovery: compute a \emph{source weight} $w_s$ for each source,
and compute `truth values' $v_{o}^{*}$ for each object $o$
\item \emph{Single truth assumption}: there is exactly one true value for each
object. This may not always hold (e.g. consider which actors star in a film)
\end{itemize}

\subsection{Gupta and Han survey}
\label{sec:gupta}

From \cite{gupta_han_survey}, slightly re-phrased by me (e.g. paper calls
sources `providers', denotes confidence by $s$\ldots)

\begin{itemize}
\item Set of sources $\mathcal{S}$, objects $\mathcal{O}$
\item Each object $o$ has as associated set of \emph{facts} $F_o$. Write
$\mathcal{F} = \bigcup_{o \in \mathcal{O}}F_o$
\item Sources \emph{provide} facts about objects. They may provide facts about
multiple objects, but only one fact per object
\item Could be formalised similar to \ref{sec:li} as follows: $f_o^s \in F_o$
is the fact provided by source $s$ for object $o$, defined for a subset of
$\mathcal{O}$
\item Truth-discovery: compute \emph{source trusts} $t_s$ for each source $s$,
and \emph{fact confidence} $c_f$ for each fact $f$
\end{itemize}

Note that general set up is more or less equivalent to in \ref{sec:li}: facts
replace values. However the definition of a truth-discovery algorithm is
different: here each fact is given a confidence score, whereas in \ref{sec:li}
we only find the most believable fact for each object.

If each fact is given a confidence score then it is simple to find most
believed fact for each object by taking the fact with highest confidence.

\subsection{Latent Dirichlet Truth Discovery}
\label{sec:ldt}

The method proposed in \cite{zhang_qi_tang} is similar to both above approaches:

\begin{itemize}
\item Set of sources $\mathcal{S}$, objects $\mathcal{O}$, facts $F_o$ for each
$o \in \mathcal{O}$
\item Each source $s$ makes claim $\texttt{Cl}_o(s) \in F_o \cup
\{\oslash\}$ for the true fact for object $o$, where $\oslash$ is special
symbol to indicate no claim is made
\item Each source has a \emph{trustworthy component} and \emph{untrustworthy
component}
\item Truth-discovery:
    \begin{itemize}
    \item Compute probability that each fact $f$ is the true fact for its
    associated object (i.e. confidence in each fact?)
    \item Compute trustworthy and untrustworthy amounts in each source
    (trustworthy amount can be considered source trustworthiness, comparable to
    other approaches)
    \end{itemize}
\end{itemize}

\subsection{Pasternack and Roth}
\label{sec:past}

In \cite{pasternack}:

\begin{itemize}
\item Set of sources $\mathcal{S}$, each with a set of claims $C_s$ ($s \in
\mathcal{S}$). Write $\mathcal{C} = \bigcup_{s \in \mathcal{S}}{C_s}$
\item Each claim $c$ has \emph{mutual exclusion} set $M_c \subseteq
\mathcal{C}$: only one claim in each $M_c$ is true. Note that $c \in M_c$
\item Truth-discovery: compute source trusts $t_s$ and claim beliefs $b_c$
\end{itemize}

This is essentially the same as \ref{sec:gupta}, if we let each mutual
exclusion set be called an object, rename claims to facts, and the facts
provided by source $s$ are simply those in $C_s$. Something like the following.
$$
\mathcal{O} = \{M_c : c \in \mathcal{C}\},
\quad
F_{M_c} = M_c
$$

The only slight problem is that under this mapping a fact (\ref{sec:gupta}
sense) may be related to multiple objects, e.g. if $c \in M_{c'}$ but $M_c \ne
M_{c'}$.

\subsection{Galland et. al algorithms}
\label{sec:galland}

Several algorithms are proposed in \cite{galland}, and each uses the following
scheme, which is initially quite different from those above (again, slightly
re-phrased by me in places):

\begin{itemize}
\item Set of sources $\mathcal{S}$, facts $\mathcal{F}$, and the \emph{real
world} $W: \mathcal{F} \rightarrow \{\texttt{True}, \texttt{False}\}$
\item Each source $s$ is a partial mapping $\mathcal{F} \rightarrow
\{\texttt{True}, \texttt{False}\}$
\item Each source $s$ has an \emph{error factor} $\epsilon(s) \in [0, 1]$ (?)
that represents the likeliness of $s$ making a mistake on the truth value of
any given fact
\item Set of \emph{queries} $\mathcal{Q}$. Each fact $f$ has a \emph{reference
query} $ref(f) \in \mathcal{Q}$ (imagine that $q\in\mathcal{Q}$ is a question,
and $f$ answers the question in some way). Any query has exactly one true fact.
Formally, for each query $q$, let $F_q = \{f \in \mathcal{F} : ref(f) = q\}$.
For each $q$ there is exactly one $f \in F_q$ with $W(f) = \texttt{True}$ \item
Truth-discovery: compute source error factors $\epsilon(s)$, and an estimate
for the real world $W$ given as a mapping $\mathcal{F} \rightarrow [0,
1]$ where 1 represents true and 0 represents false.
\end{itemize}

Some important differences here:
\begin{itemize}
\item Sources may claim a fact is \emph{false}, which is not possible in the
other approaches
\item Objects are not first-class citizens
\item Notion of queries. The set of queries (along with the reference query for
each fact) is not given as input to algorithms; it is instead used to produce a
modified set of views, where for each source $s$ and each fact $f$ such that
$s(f) = \texttt{True}$, we add a new claim $s(f')=\texttt{False}$ for each
$f' \ne f$ such that $f'$ and $f$ relate to the same query. This idea is
applicable whenever the \emph{single truth assumption} is assumed, but only for
algorithms that consider negative facts. See section 3 of \cite{galland} for
details.
\end{itemize}

I think we can view this model as a special case of the one in \ref{sec:li},
where objects (\ref{sec:li} sense) are facts, and $v_f^s$ (\ref{sec:li} sense)
is given by $s(f)$ (\ref{sec:galland} sense, when this is defined).

This is a special case since the only claimed values are \texttt{True} and
\texttt{False}, whereas in \ref{sec:li} the values can be anything.

\section{Model for the development of axioms}

The input seems to be essentially equivalent in all approaches, with the
exception of \ref{sec:galland} which has the concept of negative claims.

Output differs: in \ref{sec:li} a single true fact is selected for each object,
and in the others all facts are given a belief score in $[0, 1]$. Both
approaches ultimately \emph{rank} the facts of each object.

Initial ideas of a graph-theoretic formulation:

% Input network definition
\begin{definition}

A \emph{truth-discovery network} consists of non-empty sets $\mathcal{S}$
(sources), $\mathcal{F}$ (facts), $\mathcal{O}$ (objects), and a directed graph
$G=(V, E)$ where $V = \mathcal{S} \cup \mathcal{F} \cup \mathcal{O}$, and $E
\subseteq (\mathcal{S} \times \mathcal{F}) \cup (\mathcal{F} \times
\mathcal{O})$ satisfies the following properties:

\begin{enumerate}

\item Each $f \in \mathcal{F}$ has a unique successor node in $\mathcal{O}$,
denoted $O_f$ (i.e. each fact relates to a single object)

\item For $s \in \mathcal{S}$ and $o \in \mathcal{O}$, there is at most one $f
\in \mathcal{F}$ such that $(s, f) \in E$ and $O_f = o$ (i.e. sources can only
claim one fact per object)

\end{enumerate}

For $o \in \mathcal{O}$ we denote by $F_o$ the set $\{f \in \mathcal{F} : O_f =
o \}$.

\end{definition}

Some initial ideas for what a truth-discovery algorithm is.

% Algorithm definition
\begin{definition}
\label{def:ordinal}

A \emph{truth-discovery algorithm} $A$ assigns to each truth-discovery network
a total ordering $\preceq_\mathcal{S}^A$ on the set of sources $\mathcal{S}$
(the \emph{trust ordering}) and a total ordering $\preceq_o^A$ on the set of
facts $F_o$ for each object $o \in \mathcal{O}$.

\end{definition}

\begin{definition}
\label{def:numerical}

A \emph{truth-discovery algorithm} $A$ assigns to each truth-discovery network
a \emph{source trust} mapping $\tau: \mathcal{S} \rightarrow [0, 1]$ and
\emph{claim belief} mapping $\phi: \mathcal{F} \rightarrow [0, 1]$.

\end{definition}

\begin{definition}
\label{def:most_believed}

A \emph{truth-discovery algorithm} $A$ assigns to each truth-discovery network
a set of \emph{true facts} $\mathcal{F}^* \subseteq \mathcal{F}$ that contains
exactly one element of $F_o$ for each object $o$ (plus source trusts as per one
of definition \ref{def:ordinal} or \ref{def:numerical})

\end{definition}

\textbf{Thoughts:}
\begin{itemize}

\item Definition \ref{def:ordinal} considers only the relative order of
sources/facts, rather than assigning numerical values (as real-world algorithms
do in practise). This follows ideas in PageRank axiomatisation{\cite{altman}},
axioms for personalised ranking systems{\cite{altman_personalised}} and I think
social choice in general.

Also, numerical trust scores often do not have semantic meaning, so only the
relative scores are important anyway (definitely no semantics in Pasternack and
Roth paper \cite{pasternack}, although maybe there is in probabilistic ones
like \emph{TruthFinder}\cite{yin_han_yu} and LDT\cite{zhang_qi_tang})

\item Every algorithm that I have seen in practise gives output for trusts as
in definition \ref{def:numerical}. The majority of them also give fact belief
in this way. This also captures how much more trustworthy sources are than each
other, which is lost when only considering relative trustworthiness (e.g. the
difference between $\tau(s_1) = 0.9, \tau(s_2) = 0.89$ and $\tau(s_1) = 0.9,
\tau(s_2) = 0.01$)

\item Some algorithms only give most believed values as output (not belief
score for each fact) as per definition \ref{def:most_believed} (e.g.
\cite{li_conflicts}).

\end{itemize}

\bibliography{references}{}
\bibliographystyle{plain}

% \end{multicols}
\end{document}
